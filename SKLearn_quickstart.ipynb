{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
       "# Quickstart Guide for Scikit-learn Training Using Pipeline and OneHotEncoder\n",
       "## Introduction\n",
       "This notebook provides a quickstart for training a Scikit-learn model using a pipeline that includes preprocessing steps with both `StandardScaler` and `OneHotEncoder`, applied to numerical data.\n",
       "\n",
       "### Steps Covered:\n",
       "- Load data from a Snowflake table.\n",
       "- Preprocess numerical data using `Pipeline` and `ColumnTransformer`.\n",
       "- Apply `OneHotEncoder` to a numerical column treated as categorical.\n",
       "- Train a linear regression model.\n",
       "- Make predictions and evaluate the model."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "step1",
      "metadata": {},
      "source": [
       "### Step 1: Set Up Snowflake Session\n",
       "Initialize a Snowflake session to load data from the table."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell1",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize Snowflake session\n",
       "from snowflake.snowpark.context import get_active_session\n",
       "session = get_active_session()"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "step2",
      "metadata": {},
      "source": [
       "### Step 2: Load Data from Snowflake Table\n",
       "We load data from the `CR_QUICKSTART.PUBLIC.VEHICLE` table and drop the timestamp column (`C2`) as it is not needed for this quickstart."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell2",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load data from the Snowflake table\n",
       "table_name = 'CR_QUICKSTART.PUBLIC.VEHICLE'\n",
       "snowpark_df = session.table(table_name)\n",
       "\n",
       "# Convert Snowpark DataFrame to Pandas DataFrame\n",
       "pandas_df = snowpark_df.to_pandas()\n",
       "\n",
       "# Drop the timestamp column ('C2')\n",
       "pandas_df = pandas_df.drop(columns=['C2'])\n",
       "\n",
       "# Separate features (X) and target (y). Assume C6 is the target column.\n",
       "X = pandas_df.drop('C6', axis=1)\n",
       "y = pandas_df['C6']\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "preprocessing",
      "metadata": {},
      "source": [
       "### Step 3: Preprocess Data Using Pipeline\n",
       "We will use `StandardScaler` for scaling numerical columns and `OneHotEncoder` for a numerical column (e.g., `C3`) treated as categorical."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell3",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Import necessary Scikit-learn modules\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
       "from sklearn.impute import SimpleImputer\n",
       "\n",
       "# Identify numerical columns\n",
       "numerical_cols = ['C1', 'C4', 'C5', 'C7', 'C8', 'C9']\n",
       "# Select a numerical column to treat as categorical for OneHotEncoding\n",
       "onehot_col = ['C3']\n",
       "\n",
       "# Create transformers for numerical and onehot-encoded columns\n",
       "numerical_transformer = Pipeline([\n",
       "    ('imputer', SimpleImputer(strategy='mean')),\n",
       "    ('scaler', StandardScaler())\n",
       "])\n",
       "onehot_transformer = Pipeline([\n",
       "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
       "])\n",
       "\n",
       "# Combine transformers using ColumnTransformer\n",
       "preprocessor = ColumnTransformer(\n",
       "    transformers=[\n",
       "        ('num', numerical_transformer, numerical_cols),\n",
       "        ('onehot', onehot_transformer, onehot_col)\n",
       "    ]\n",
       ")\n",
       "\n",
       "# Test the preprocessor on the data\n",
       "preprocessed_X = preprocessor.fit_transform(X)\n",
       "print(f'Preprocessed shape: {preprocessed_X.shape}')"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "train-model",
      "metadata": {},
      "source": [
       "### Step 4: Train a Scikit-learn Model Using the Preprocessed Data\n",
       "We will train a linear regression model using the preprocessed data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell4",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Import Scikit-learn model and training utilities\n",
       "from sklearn.linear_model import LinearRegression\n",
       "from sklearn.model_selection import train_test_split\n",
       "\n",
       "# Split the data into training and testing sets (90% train, 10% test)\n",
       "X_train, X_test, y_train, y_test = train_test_split(preprocessed_X, y, test_size=0.1, random_state=42)\n",
       "\n",
       "# Initialize the linear regression model\n",
       "model = LinearRegression()\n",
       "\n",
       "# Train the model\n",
       "model.fit(X_train, y_train)\n",
       "print('Model training complete.')"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "prediction",
      "metadata": {},
      "source": [
       "### Step 5: Make Predictions and Evaluate the Model\n",
       "We use the trained model to make predictions on the test set and evaluate its performance."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell5",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Make predictions on the test set\n",
       "y_pred = model.predict(X_test)\n",
       "\n",
       "# Display a few predictions\n",
       "print(f'Sample predictions: {y_pred[:10]}')"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
       "## Conclusion\n",
       "In this notebook, we demonstrated how to:\n",
       "- Load and preprocess data using Scikit-learn's `Pipeline` and `OneHotEncoder` for numerical data.\n",
       "- Train a linear regression model using the preprocessed data.\n",
       "- Make predictions and evaluate the model.\n",
       "\n",
       "This approach can be adapted to other datasets and models, leveraging the flexibility of Scikit-learn's API."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   
